---
title: 프로젝트 5주차
date: 2024-10-02 16:30:00 +0900
categories: [Kafka]
tags: [kafka]     # TAG names should always be lowercase
authors: [LoafingCat]
---

# S3 2 DB 2 MLflow


## 목차

1. 개요
2. 실행환경
3. 코드 설명
4. 이슈

### 개요

이 시스템의 목적은 Amazon S3에 저장된 데이터를 데이터베이스로 전송하고, 이후 이 데이터를 MLflow로 전송하여 머신러닝 모델의 학습 및 실험을 관리하는 것임. 데이터 파이프라인의 효율성과 자동화를 위한 시스템.

### 실행환경

- 공통 환경

		Python 3.11.9
		Airflow 2.9.3
		boto3
		pandas
		mlflow
		scikit-learn

**postgres**

	SQLAlchemy

**redis**

	rediscluster



### 코드 설명

#### S3 ~ postgres ~ mlflow


		bucket_name = 'team06-mlflow-feature'
		s3_object_name = 'iris1.csv'

- bucket_name에 s3에 저장된 데이터 버킷 이름 설정
- s3_object_name 읽어올 파일을 입력

		AWS_ACCESS_KEY_ID = os.getenv("AWS_ACCESS_KEY_ID")
		AWS_SECRET_ACCESS_KEY = os.getenv("AWS_SECRET_ACCESS_KEY")
		S3_REGION = 'ap-northeast-2'

- AWS에 접근하기 위한 자격 증명을 환경 변수에서 가져옴
- S3_REGION 리전 설정

		db_user = os.getenv("POSTGRES_USER")
		db_password = os.getenv("POSTGRES_PASSWORD")
		db_host = 'postgres'
		db_port = '5432'
		db_name = 's32db'

- 유저와 비밀번호는 환경변수에서 가져오게끔
- 서비스 이름, 포트, db 이름을 설정해줌

		def read_s3_and_store_to_postgres():
			# AWS 자격 증명으로 S3 클라이언트 생성
			s3 = boto3.client('s3', 
							region_name=S3_REGION,
							aws_access_key_id=AWS_ACCESS_KEY_ID,
							aws_secret_access_key=AWS_SECRET_ACCESS_KEY)

			# S3에서 CSV 객체 가져오기
			csv_obj = s3.get_object(Bucket=bucket_name, Key=s3_object_name)
			body = csv_obj['Body'].read().decode('utf-8')

			# 파일 내용을 pandas DataFrame으로 변환
			data = pd.read_csv(io.StringIO(body), sep=';')

			# SQLAlchemy를 사용하여 PostgreSQL 엔진 생성
			engine = create_engine(f'postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}')

			# 데이터프레임을 PostgreSQL에 로드
			data.to_sql('iris_data', engine, if_exists='replace', index=True)
			print("Data has been loaded into PostgreSQL.")

- boto3 라이브러리를 사용하여 S3 클라이언트를 생성하고, 지정된 버킷과 파일 이름으로 CSV 파일을 가져옴

- 
CSV 파일의 내용을 pandas 데이터프레임으로 변환한 후, SQLAlchemy를 통해 PostgreSQL에 연결하여 데이터를 iris_data 테이블에 저장
		
		# Iris 데이터 읽기
		iris_data = pd.read_sql('SELECT * FROM iris_data', engine)

		# 특징(X)과 레이블(y) 분리
		X = iris_data.drop(columns='Species')
		y = iris_data['Species']  

		# 훈련 데이터와 테스트 데이터로 분리
		X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

		# MLflow 설정
		mlflow.set_tracking_uri("http://mlflow:8080")
		mlflow.set_experiment("testjun")

		# MLflow 실행 시작
		mlflow.start_run()

		# 모델 훈련
		model = RandomForestClassifier(n_estimators=100)
		model.fit(X_train, y_train)

		# 모델 저장
		model_path = "iris_model"
		mlflow.sklearn.log_model(model, model_path)

		# 모델 레지스트리에 등록
		model_uri = f"runs:/{mlflow.active_run().info.run_id}/{model_path}"
		mlflow.register_model(model_uri, "IrisModel")

		# MLflow 실행 종료
		mlflow.end_run()

		print("Model has been trained and logged to MLflow.")

- PostgreSQL에서 iris_data 테이블의 데이터를 읽어옴

- 데이터를 특징(X)과 레이블(y)로 분리한 후, 훈련 데이터와 테스트 데이터로 나눔

- MLflow를 설정하고, 랜덤 포레스트 모델을 훈련시킨 뒤, 이걸 MLflow에 기록하고 레지스트리에 등록

		default_args = {
			'owner': 'airflow',
			'depends_on_past': False,
			'start_date': datetime(2023, 9, 26),
			'retries': 1,
		}

		dag = DAG('iris_model', default_args=default_args, schedule_interval='@daily')

		task_read_s3_and_store_to_postgres = PythonOperator(
			task_id='read_s3_and_store_to_postgres',
			python_callable=read_s3_and_store_to_postgres,
			dag=dag,
		)

		task_load_data_and_train_model = PythonOperator(
			task_id='load_data_and_train_model',
			python_callable=load_data_and_train_model,
			dag=dag,
		)

		task_read_s3_and_store_to_postgres >> task_load_data_and_train_model

- default_args: DAG의 기본 인수들을 설정. 소유자, 과거 의존성, 시작 날짜, 재시도 수 등등

- dag: DAG를 정의하고, 매일 실행되도록 설정

- PythonOperator: 두 개의 작업을 정의. 하나는 S3에서 데이터를 읽고 PostgreSQL에 저장하는 작업, 다른 하나는 데이터를 읽어 모델을 훈련시키는 작업

- 마지막에 작업의 실행 순서를 정의함. 첫 번째 작업이 완료된 후 두 번째 작업이 실행된다는 뜻


#### S3 ~ redis ~ mlflow

- 버킷 이름, 파일 이름, aws 자격증명은 위 코드와 동일함.

	redis_host = 'redis-cluster'  # Redis 서비스 이름
	redis_port = '6379'

- Redis 클러스터의 호스트와 포트 설정


		def read_s3_and_store_to_redis():
			try:
				# Redis 클러스터 접속 정보
				startup_nodes = [{"host": redis_host, "port": redis_port}]
				redis_client = RedisCluster(startup_nodes=startup_nodes, decode_responses=True)

				# AWS 자격 증명으로 S3 클라이언트 생성
				s3 = boto3.client('s3', 
								region_name=S3_REGION,
								aws_access_key_id=AWS_ACCESS_KEY_ID,
								aws_secret_access_key=AWS_SECRET_ACCESS_KEY)

				# S3에서 CSV 객체 가져오기
				csv_obj = s3.get_object(Bucket=bucket_name, Key=s3_object_name)
				body = csv_obj['Body'].read().decode('utf-8')
				data = pd.read_csv(StringIO(body))

				for index, row in data.iterrows():
					redis_client.set(f"row:{index}", json.dumps(row.to_dict()))

				print("Data has been imported to Redis.")
			except Exception as e:
				print(f"Error reading from S3 or storing to Redis: {e}")

- Redis 클라이언트 생성: Redis 클러스터에 연결

- S3 클라이언트 생성: AWS 자격 증명을 사용하여 S3 클라이언트 생성

- CSV 파일 읽기: S3에서 CSV 파일을 가져와 내용을 읽고 pandas 데이터프레임으로 변환

- Redis에 저장: 각 행을 JSON 형식으로 변환하여 Redis에 저장. 키는 row:{index} 형식

- 예외 처리: S3 읽기 또는 Redis 저장 중 오류가 발생하면 오류 메시지를 출력함

		def load_from_redis_and_train_model():
			# Redis 클러스터 접속 정보
			startup_nodes = [{"host": redis_host, "port": redis_port}]
			redis_client = RedisCluster(startup_nodes=startup_nodes, decode_responses=True)

			data = []
			index = 0

			try:
				while True:
					row = redis_client.get(f"row:{index}")
					if row is None:
						break
					data.append(json.loads(row))
					index += 1

				iris_data = pd.DataFrame(data)

				# MLflow 설정
				mlflow.set_tracking_uri("http://mlflow:8080")
				mlflow.set_experiment("iris_experiment")

				# MLflow 실행 시작
				mlflow.start_run()

				# 특징(X)과 레이블(y) 분리
				X = iris_data.drop(columns='Species')
				y = iris_data['Species']

				# 훈련 데이터와 테스트 데이터로 분리
				X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

				# 모델 훈련
				model = RandomForestClassifier(n_estimators=100)
				model.fit(X_train, y_train)

				# 모델 저장
				model_path = "iris_model"
				mlflow.sklearn.log_model(model, model_path)

				# 모델 레지스트리에 등록
				model_uri = f"runs:/{mlflow.active_run().info.run_id}/{model_path}"
				mlflow.register_model(model_uri, "IrisModel")

				# MLflow 실행 종료
				mlflow.end_run()

				print("Model has been trained and logged to MLflow.")
			except Exception as e:
				print(f"Error loading data from Redis or training model: {e}")

- Redis 클라이언트 생성: Redis 클러스터에 연결

- 데이터 불러오기: Redis에서 저장된 데이터를 반복적으로 가져와 리스트에 저장. row:{index} 형식의 키를 사용하여 데이터를 가져옴.

- 데이터프레임 생성: 가져온 데이터를 pandas 데이터프레임으로 변환

- MLflow 설정: MLflow 서버 URL과 실험 이름을 설정.

- 모델 훈련: 특징(X)과 레이블(y)을 분리한 후, 훈련 데이터와 테스트 데이터로 나누고, 랜덤 포레스트 모델을 훈련함

- 모델 저장: 훈련한 모델을 MLflow에 기록하고 레지스트리에 등록

- 마지막은 예외 처리: Redis에서 데이터 불러오기 또는 모델 훈련 중 오류나면 오류 메세지 출력

		default_args = {
			'owner': 'airflow',
			'depends_on_past': False,
			'start_date': datetime(2023, 9, 26),
			'retries': 1,
		}

		dag = DAG('redis', default_args=default_args, schedule_interval='@daily')

		task_read_s3_and_store_to_redis = PythonOperator(
			task_id='read_s3_and_store_to_redis',
			python_callable=read_s3_and_store_to_redis,
			dag=dag,
		)

		task_load_from_redis_and_train_model = PythonOperator(
			task_id='load_from_redis_and_train_model',
			python_callable=load_from_redis_and_train_model,
			dag=dag,
		)

		task_read_s3_and_store_to_redis >> task_load_from_redis_and_train_model

postgres의 경우와 동일함

### 이슈

1. 라이브러리 없음

사용하여는 라이브러리가 airflow에 있어야함. no module name~ 이라는 오류가 발생한다면, airflow 이미지를 빌드할때 필요 모듈들을 같이 넣어줘야함.

2. s3_object_name 경로

맨 앞에 /(루트) 경로를 입력하면 오류가 생김. 필요없으니 붙이지 말자.

3. SQLAlchemy

postgres의 경우 연결하기 위해선 엔진이 필요하다

SQLAlchemy의 create_engine을 이용하여 엔진을 생성해주자.

engine = create_engine(f'postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}')


# prometheus

## 목차

1. 개요
2. 코드 설정
3. 사용법


### 개요

Prometheus는 시계열 데이터 수집 및 모니터링을 위한 오픈 소스 시스템으로, 강력한 쿼리 언어와 자동 서비스 탐지 기능을 제공한다. 다양한 메트릭을 실시간으로 분석하고 경고를 설정할 수 있어서 클라우드 환경에 적합하다.



### 코드 설정

	spec:
		nodeSelector:
			type: worker  # worker 노드에만 배포
		containers:
		- name: prometheus
			image: prom/prometheus:latest
			args:
			- "--config.file=/etc/prometheus/prometheus.yml"  # ConfigMap에서 설정 파일을 사용
			- "--storage.tsdb.path=/prometheus"  # 메트릭 데이터 저장 경로
			ports:
			- containerPort: 9090  # Prometheus 기본 포트
			volumeMounts:
			- name: prometheus-storage
			mountPath: /prometheus  # 기본 메트릭 저장 경로
			- name: prometheus-config  # ConfigMap을 마운트
			mountPath: /etc/prometheus
		volumes:
		- name: prometheus-storage
			persistentVolumeClaim:
			claimName: prometheus-pvc  # PVC를 통해 EFS 볼륨에 연결
		- name: prometheus-config  # ConfigMap 정의
			configMap:
			name: prometheus-config

**유의해서 봐야할 부분**

- args: 아래에 configmap에서 설정 파일을 사용하게 설정. 아래 경로는 prometheus의 주요 구성 파일이다.

또한 매트릭 저장 경로를 지정한다. 이 경로는 pv에 마운트 됨


### 사용법

1. 지정한 node port인 30111로 접근. <ec2_public_ip>:30111

2. 

![alt text](<이미지 25.png>)

표시된 버튼을 클릭하면 

![alt text](<이미지 26.png>)

사용 가능한 매트릭 열람이 가능하다.

# grafana

## 목차

1. 개요
2. 코드설정
3. 사용법

		apiVersion: v1
		kind: PersistentVolumeClaim
		metadata:
		name: grafana-efs-claim
		spec:
		accessModes:
			- ReadWriteMany
		resources:
			requests:
			storage: 1Gi  # 요청하는 스토리지 크기
		storageClassName: grafana-storageclass  # 사용 중인 StorageClass 이름

		---
		apiVersion: apps/v1
		kind: Deployment
		metadata:
		name: grafana
		spec:
		replicas: 1
		selector:
			matchLabels:
			app: grafana
		template:
			metadata:
			labels:
				app: grafana
			spec:
			containers:
				- name: grafana
				image: grafana/grafana:latest
				ports:
					- containerPort: 3000
				env:
					- name: GF_SECURITY_ADMIN_PASSWORD
					value: "admin"  # 비밀번호
				volumeMounts:
					- mountPath: /var/lib/grafana  # Grafana의 데이터 저장 경로
					name: grafana-storage
			volumes:
				- name: grafana-storage
				persistentVolumeClaim:
					claimName: grafana-efs-claim  # PVC 이름

		---
		apiVersion: v1
		kind: Service
		metadata:
		name: grafana
		spec:
		type: NodePort  # ClusterIP에서 NodePort로 변경
		ports:
			- port: 3000
			targetPort: 3000
			nodePort: 30098  # 원하는 포트 설정
		selector:
			app: grafana

- 생성한 대쉬보드나 연결 설정 등 저장이 필요하기 때문에 efs 1기가 붙여줌



### 사용법

1. grafana에 prometheus 연동

![alt text](<이미지 27.png>)

2. prometheus의 서비스 이름과 지정한 포트를 입력해준다.

![alt text](<이미지 29.png>)

3. 연결이 잘 됐는지 확인

![alt text](<이미지 30.png>)

4. dashboard로 가서 새로운 폴더나 대쉬보드 생성

![alt text](<이미지 31.png>)

5. 새로운 대쉬보드나 기존의 것을 edit 가능

![alt text](<이미지 39.png>)

![alt text](<이미지 38.png>)

6. 매트릭을 검색하거나 직접 쿼리문 작성

![alt text](<이미지 40.png>)

![alt text](<이미지 36.png>)

이렇게 해서 원하는 정보를 시각화 하여 볼 수 있다.



# exporter

## 목차

1. 개요
2. 코드설명
3. 사용법
	- prometheus config
4. 유의사항
----

### 개요

Exporter는 Prometheus의 핵심 구성 요소로, 다양한 시스템의 메트릭을 수집하고 이를 Prometheus에 통합하여 모니터링 및 경고 시스템을 구축하는 데 중요한 역할을 함. 이를 통해 운영자는 시스템 성능을 실시간으로 감시하고, 문제를 조기에 발견하여 대응할 수 있다.

### 코드설명

**es-exporter**

	apiVersion: apps/v1
	kind: Deployment
	metadata:
	name: elasticsearch-exporter
	labels:
		app: elasticsearch-exporter
	spec:
	replicas: 1
	selector:
		matchLabels:
		app: elasticsearch-exporter
	template:
		metadata:
		labels:
			app: elasticsearch-exporter
		spec:
		containers:
		- name: elasticsearch-exporter
			image: prometheuscommunity/elasticsearch-exporter:latest
			args:
			- '--es.uri=http://elasticsearch:9200/'  # 서비스 이름
			ports:
			- containerPort: 9114  # 기본 포트
			env:
			- name: ES_USERNAME
			valueFrom:
				secretKeyRef:
				name: db
				key: ELASTICSEARCH_USERNAME
			- name: ES_PASSWORD 
			valueFrom:
				secretKeyRef:
				name: db
				key: ELASTICSEARCH_PASSWORD

	---
	apiVersion: v1
	kind: Service
	metadata:
	name: elasticsearch-exporter
	labels:
		app: elasticsearch-exporter
	spec:
	type: NodePort
	ports:
	- name: metrics
		port: 9114
		targetPort: 9114
		nodePort: 30333
	selector:
		app: elasticsearch-exporter

- 모든 exporter들은 args 설정이 가장 중요함. args 작성 방식이 다 다른데 각 이미지의 github 밑 docker hub에서 작성 방식을 찾아봐야한다. 다만 공식에서 설명하는 방법이 되지 않는 경우도 있는데 이 경우는 보편적으로 쓰는 방식이나 llm이나 구글링을 추천.

- 서비스에 node port 설정은 웹에서 매트릭이 잘 불러와졌는지, 혹은 연결이 잘 되었는지 확인하기 위해서이다. 보통 연결이 안됐을 때는 up이 들어간 매트릭 이름에서 0 또는 1로 상태를 표시해준다. 0은 연결 안됨, 1은 연결됨.

**kafka-exporter**

	spec:
		containers:
		- name: kafka-exporter
			image: danielqsj/kafka-exporter:latest
			args:
			- "--kafka.server=kafka-0:9092"  
			- "--kafka.server=kafka-1:9092"
			- "--kafka.server=kafka-2:9092" 
			ports:
			- containerPort: 9308

- 다른 설정은 동일하고 args에서 인자를 불러오는 부분만 주의하면 된다. 모든 브로커를 봐야하므로 모두 연결해준다.

**mongodb-exporter**

	spec:
		nodeSelector:
			type: worker  # worker 노드에 배포
		containers:
		- name: mongodb-exporter
			image: bitnami/mongodb-exporter:latest
			ports:
			- containerPort: 9216  # MongoDB Exporter 기본 포트
			env:
			- name: MONGODB_URI
			value: "mongodb://mongodb:27017/mongo?replicaSet=MainRepSet"  # MongoDB 연결 URI

- mongodb는 value 값의 uri 설정이 가장 중요함

**postgre-exporter**

	value: "user=$(POSTGRES_USER) password=$(POSTGRES_PASSWORD) host=postgres port=5432 dbname=s32db sslmode=disable"
			ports:
				- containerPort: 9187
			command: ["/bin/sh", "-c"]
			args:
				- |
				/postgres_exporter --web.listen-address=:9187 --web.telemetry-path=/metrics


- value와 command가 겹치는 것처럼 보이는 이유:
value에서 DSN을 설정하는 것과 command에서 Exporter를 실행하는 것은 서로 다른 목적. DSN은 데이터베이스 연결 정보를 제공하고, Exporter는 메트릭을 수집하고 노출하는 역할을 한다.

- 결론:
Exporter가 PostgreSQL 데이터베이스에 연결하고, 메트릭을 수집하기 위한 필수적인 정보와 실행 환경을 설정하는 것이다. 각 요소는 서로 보완적인 역할을 하며, PostgreSQL Exporter가 제대로 작동하기 위해 함께 필요함.

**redis**

	value: "redis-cluster:6379"

- redis 서비스 이름과 지정한 포트 이름만 vaule 값에 넣어주면 된다.


### 유의사항

**args에 인자값 넣는 방식**

이 부분에서 가장 많은 시행착오를 거쳤다. 각 이미지에 맞는 방식을 찾아야 한다.


### 사용법

#### prometheus config


		apiVersion: v1
		kind: ConfigMap
		metadata:
		name: prometheus-config
		data:
		prometheus.yml: |
			global:
			scrape_interval: 15s

			alerting:
			alertmanagers:
			- static_configs:
				- targets:
				- 'alertmanager:9093'
			
			scrape_configs:
			- job_name: 'prometheus'
				static_configs:
				- targets: ['localhost:9090']

			- job_name: 'postgres-exporter'  # PostgreSQL Exporter 추가
				static_configs:
				- targets: ['postgres-exporter:9187']  # PostgreSQL Exporter 서비스 이름과 포트

			- job_name: 'kafka-exporter'  # Kafka Exporter 추가
				static_configs:
				- targets: ['kafka-exporter:9308']  # Kafka Exporter 서비스 이름과 포트

			- job_name: 'redis-exporter'
				static_configs:
				- targets: ['redis-exporter:9121']

			- job_name: 'mongodb-exporter'  # MongoDB Exporter 추가
				static_configs:
				- targets: ['mongodb-exporter:9216']

			- job_name: 'elasticsearch-exporter'  # Elasticsearch Exporter 추가
				static_configs:
				- targets: ['elasticsearch-exporter:9114']

		alert.rules: |
			groups:
			- name: server-down-alert
				rules:
				- alert: PostgresDown
					expr: pg_up == 0
					for: 1m
					labels:
					severity: critical
					annotations:
					summary: "PostgreSQL instance is down"
					description: "PostgreSQL instance {{ $labels.instance }} is down."


위 코드는 prometheus의 confimap 설정파일이다.

job 이름을 지정해주고 앞서 정의했던 exporter들의 서비스 이름과 포트 이름을 지정해주면 된다.



### 유의사항

정상 작동한다면 up과 관련된 매트릭 정보에서 1이 뜰것이고 아니라면 0이 뜰 것이다.

![alt text](<이미지 41.png>)

postgres의 매트릭 정보를 웹에 띄운것인데 이처럼 pg_up 매트릭이 있고 1이 떠있는걸 볼 수 있다. 만약 0이 떠있다면 애플리케이션에 제대로 접근하지 못했다는 뜻이니 디버깅을 해보도록 하자.






