---
title: Hadoop 구동원리
date: 2024-06-21 16:30:00 +0900
categories: [Information]
tags: [information]     # TAG names should always be lowercase
authors: [LoafingCat]
---

# 하둡 분산파일시스템(HDFS)

## 하둡이란?

Hadoop은 Reliable, Scalable하게 분산 처리를 하기 위한 오픈 소스 소프트웨어이다. 

Hadoop은 Map-Reduce라는 단순한 데이터 처리 모델을 사용함으로써 여러 대의 컴퓨터를 통해 손쉽게 대규모 데이터를 처리하고자 한다.
분산 파일 시스템인 **HDFS**(Hadoop Distributed File System)에 데이터를 저장하여 처리한다. 

이러한 방식은 Disk I/O에 의해 성능 저하를 유발하며, 추후에 In-Memory 방식으로 처리하는 Spark가 등장하게 되었다.

## 블록 크기 분할과 추상화에 따른 이점

    - 같은 파일을 분산 처리하여 데이터 처리 성능을 개선할 수 있음
    - 블록 단위로 나누어 저장하기 때문에 디스크 사이즈보다 더 큰 파일을 보관할 수 있음
    - 파일 단위보다 블록 단위로 추상화를 하면 스토리지의 서브 시스템을 단순하게 만들 수 있으며, 파일 탐색 지점이나 메타정보를 저장할 때 사이즈가 고정되어 있으므로 구현이 용이함

    - 내고장성을 제공하는데 필요한 복제(replication)을 구현할 때 매우 적합

    - 같은 노드에 같은 블록이 존재하지 않도록 복제하여 노드가 고장일 경우 다른 노드의 블록으로 복구할 수 있음


## 하둡에서 블록(Block) 하나의 크기가 큰 이유는?
    -HDFS의 블록은 128MB와 같이 매우 큰 단위

    -전체 블록 정보에 대한 메타 정보 크기가 작아짐 (네임노드 메모리 효율적 사용가능)

    -블록이 큰 이유는 탐색 비용을 최소화할 수 있기 때문

    -블록이 크면 하드디스크에서 블록의 시작점을 탐색하는 데 걸리는 시간을 줄일 수 있고, 네트워크를 통해 데이터를 전송하는데 더 많은 시간을 할당이 가능함

