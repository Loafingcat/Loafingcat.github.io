---
title: mlops
date: 2025-05-06 16:30:00 +0900
categories: [Mlops]
tags: [mlops]     # TAG names should always be lowercase
authors: [LoafingCat]
---


# 목차

[1. 개요](#1-개요)

[2. 목적](#2-목적)

[3. 특징](#3-특징)

[4. 기술요소](#4-기술요소)

[5. 장점](#5-장점)

[6. 단점](#6-단점)

[7. 사용사례](#7-사용사례)

[8. devops와의 차이점](#8-devops와의-차이점)




----------------------------------------

## 1. 개요


MLOps(Machine Learning + Operations)

프로덕션 환경에서 머신러닝 모델이 프로덕션 환경에서 지속적이고 안정적으로 배포되도록 유지, 관리, 모니터링 해주는 것.

머신러닝 개발 뿐만이 아닌, 데이터를 수집 분석하고 학습하여 배포하는 과정까지 포함한다(AI 생애 주기가 포함됨).

ML, DevOps, DE의 교차점.


## 2. 목적


1. 모델 배포속도 향상

모델 학습, 평가, 패키징, 배포에 이르는 일련의 과정을 자동화된 파이프라인으로 구축한다. 

코드 변경뿐만 아니라 새로운 모델 버전이 준비될 때마다 사전 정의된 테스트를 거쳐 자동으로 빌드되고 배포될 수 있도록 CI/CD 워크플로우를 적용함. 

이를 통해 모델 배포에 필요한 수작업과 대기 시간을 최소화하고, 모델 검증 절차를 자동화하여 안정성을 높이며 배포 속도 단축이 가능함.

2. 모델 신뢰성 및 안정성 확보

시간이 지나며 모델의 성능이 저하 됐을 때 MLOps는 배포된 모델의 예측 결과, 지연 시간, 처리량 등의 다양한 지표를 지속적으로 모니터링하는 시스템을 만듦.

모델 성능(정확도)과 입력된 데이터의 통계적 특성변화(이건 안해봄)를 추적해서 이상 징후가 발생하면 담당자에게 알림이 가도록 설계가 가능함.

또한 성능 저하가 감지되면 다시 재학습을 시키고 이전의 버전으로 롤벡하는 등의 자동화된 메커니즘이 가능함.

이로인해 신뢰성과 안정성이 지켜짐.

3. 확장성 보장

MLOps는 모델 서빙을 위해 Docker와 같은 컨테이너 기술을 활용하는데 k8s와 같은 컨테이너 오케스트레이션 플랫폼 위에서 모델을 배포함. 

모델 애플리케이션을 표준화된 단위로 관리하고, 트래픽 부하에 따라 서빙 인스턴스 수를 늘리거나 줄일 수 있음.

클라우드 환경의 확장 가능한 스토리지 및 컴퓨팅 자원을 활용해서 대규모 데이터 처리 및 모델 학습을 지원함으로써 인프라의 유연성과 확장성 확보가 가능해진다.

4. 협업 개선

전통적으로는 데이터 과학자는 모델 개발에 집중하고, 엔지니어는 모델을 서비스에 통합하고  운영팀은 인프라를 관리하는 식으로 분리되었음. 각 팀이 사용하는 도구, 프로세스, 목표가 다르기 때문에 모델 배포 과정에서 오해, 지연, 통합하는데 문제가 자주 발생.

MLOps는 데이터 과학자, 엔지니어, 운영팀이 공통된 목적을 가지고 동일한 파이프라인과 도구 세트를 사용하게 됨. 코드, 데이터, 모델, 실험 결과 등의 모든 관련 정보가 중앙에서 관리되고 공유되어 투명성을 높임.

자연스레 팀간의 의존성을 줄이고 자동화된 워크플로우는 오류를 최소화 시킴. 이로인해 팀 간의 소통이 원할해지고 원만한 협업 가능.

5. 재현성 및 투명성

코드(git), 데이터셋(버전관리 시스템 또는 피쳐스토어), 모델아티팩트 종속성 라이브러리 등 모델 개발에 사용된 모든 구성요소에 대한 체계적인 버전 관리를 적용함.


## 3. 특징

1. 자동화된 파이프라인: 데이터 수집/전처리, 모델 학습, 평가, 검증, 배포에 이르는 과정을 자동화함.

2. 지속적인 통합 및 배포 (CI/CD): 코드 변경뿐만 아니라 데이터 변경, 모델 변경에 대해서도 지속적으로 테스트하고 배포한다.

3. 모니터링 및 로깅: 모델 성능, 데이터 드리프트, 시스템 상태 등을 지속적으로 모니터링하고 로깅한다.

4. 버전 관리: 코드, 데이터, 모델, 환경 설정 등 모든 자산에 대한 체계적인 버전 관리를 수행한다.

5. 재현 가능한 환경: 동일한 데이터와 코드로 항상 동일한 모델을 학습할 수 있는 환경을 제공한다.

6. 실험 관리: 다양한 모델 실험을 추적하고 관리하는 기능을 포함한다.


## 4. 기술요소

데이터 처리 및 파이프라인: Apache Spark, Kafka, Apache Flink

모델 학습 프레임워크: TensorFlow, PyTorch, Scikit-learn

모델 레지스트리: MLflow, SageMaker Model Registry

CI/CD 도구: Jenkins, GitLab CI, GitHub Actions, Azure DevOps, CircleCI

컨테이너화 및 오케스트레이션: Docker, Kubernetes

모니터링 및 알림: Prometheus, Grafana, ELK Stack, Datadog

클라우드 플랫폼 서비스: AWS SageMaker, Google Cloud AI Platform, Azure Machine Learning

피처 스토어: Feast, Redis


## 5. 장점

빠른 시장 출시 (Time-to-Market): 모델 개발부터 배포까지의 시간 단축

모델 성능 개선 및 유지: 지속적인 모니터링과 재학습을 통해 모델 성능을 최신 상태로 유지 가능

운영 효율성 증대: 수동적인 작업을 자동화하여 운영 부담을 줄임

비용 절감: 효율적인 리소스 관리를 통해 운영 비용을 최적화

리스크 감소: 자동화된 테스트 및 검증 절차를 통해 배포 실패 및 모델 오류의 위험을 줄임

규제 준수 및 감사 용이: 모든 과정을 기록하고 관리하여 규제 준수 및 감사에 유리하다


## 6. 단점

복잡성: 데이터 과학, 소프트웨어 엔지니어링, IT 운영 등 다양한 분야의 전문 지식이 요구되어 초기 설정 및 운영이 복잡할 수 있음

초기 투자 비용 및 시간: 적절한 도구와 인프라를 구축하고 프로세스를 정립하는 데 상당한 시간과 비용이 소요될 수 있다. 사업 규모를 잘 고려해야함

전문 인력 부족: MLOps 전반에 대한 이해와 경험을 가진 인력을 확보하기 어려움

잦은 변화: 머신러닝 기술과 도구가 빠르게 발전하므로 지속적인 학습과 업데이트가 필요함


## 7. 사용사례

추천 시스템: 사용자 행동 데이터를 기반으로 실시간으로 모델을 업데이트하고 서빙

이상 탐지/사기 탐지: 금융 거래, 네트워크 활동 등에서 이상 징후를 탐지하는 모델을 지속적으로 운영

예측 유지보수: 장비 센서 데이터를 분석하여 고장을 예측하는 모델을 배포하고 관리

자율 주행: 차량 센서 데이터를 기반으로 하는 복잡한 모델을 안전하고 신뢰성 있게 배포하고 업데이트

의료 영상 분석: 의료 영상 데이터를 활용한 진단 모델을 개발하고 운영


## 8. devops와의 차이점




aws